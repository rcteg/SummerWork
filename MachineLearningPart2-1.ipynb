{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Housing Regression from Kaggle 2: Advanced Techniques\n",
    "\n",
    "### In this part, we are attempting to identify columns and data values that have NaN values (null values), then dropping them so that we don't have NaN values.\n",
    "\n",
    "#### 1: Import pandas and our training/testing data files.\n",
    "\n",
    "#### 2: Create a list of the column names and create an empty list to store the names of columns that have NaN values.\n",
    "\n",
    "#### 3: Uses a for loop to go through the list of column names, detect if there are any NA values, and if so, add them to the empty list.\n",
    "\n",
    "#### 4: Prints the list of columns that have empty values.\n",
    "\n",
    "#### 5: Creates a new dataframe identical in size to data but with True and False replacing actual values, True being for an NaN value.\n",
    "\n",
    "#### 6: Creates a one dimensional array with axis labels (column names) that contain the sum of the 'True' Values, then prints this.\n",
    "\n",
    "#### 7: Prints only the columns that are known to have NaN values and their sums by combining both method above.\n",
    "\n",
    "#### 8: Drops the columns that have NaN values and prints out the new column list for both the training and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the columns that have empty values:\n",
      "\n",
      "['LotFrontage', 'Alley', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
      "\n",
      "These are the numbers of 'NaN' values in for every column in the data:\n",
      "\n",
      "Id                  0\n",
      "MSSubClass          0\n",
      "MSZoning            0\n",
      "LotFrontage       259\n",
      "LotArea             0\n",
      "Street              0\n",
      "Alley            1369\n",
      "LotShape            0\n",
      "LandContour         0\n",
      "Utilities           0\n",
      "LotConfig           0\n",
      "LandSlope           0\n",
      "Neighborhood        0\n",
      "Condition1          0\n",
      "Condition2          0\n",
      "BldgType            0\n",
      "HouseStyle          0\n",
      "OverallQual         0\n",
      "OverallCond         0\n",
      "YearBuilt           0\n",
      "YearRemodAdd        0\n",
      "RoofStyle           0\n",
      "RoofMatl            0\n",
      "Exterior1st         0\n",
      "Exterior2nd         0\n",
      "MasVnrType          8\n",
      "MasVnrArea          8\n",
      "ExterQual           0\n",
      "ExterCond           0\n",
      "Foundation          0\n",
      "                 ... \n",
      "BedroomAbvGr        0\n",
      "KitchenAbvGr        0\n",
      "KitchenQual         0\n",
      "TotRmsAbvGrd        0\n",
      "Functional          0\n",
      "Fireplaces          0\n",
      "FireplaceQu       690\n",
      "GarageType         81\n",
      "GarageYrBlt        81\n",
      "GarageFinish       81\n",
      "GarageCars          0\n",
      "GarageArea          0\n",
      "GarageQual         81\n",
      "GarageCond         81\n",
      "PavedDrive          0\n",
      "WoodDeckSF          0\n",
      "OpenPorchSF         0\n",
      "EnclosedPorch       0\n",
      "3SsnPorch           0\n",
      "ScreenPorch         0\n",
      "PoolArea            0\n",
      "PoolQC           1453\n",
      "Fence            1179\n",
      "MiscFeature      1406\n",
      "MiscVal             0\n",
      "MoSold              0\n",
      "YrSold              0\n",
      "SaleType            0\n",
      "SaleCondition       0\n",
      "SalePrice           0\n",
      "Length: 81, dtype: int64\n",
      "\n",
      "These are the new data columns with the columns that had 'NaN' values dropped\n",
      "\n",
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
      "       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
      "       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n",
      "       'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
      "       'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive',\n",
      "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n",
      "\n",
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
      "       'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
      "       'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n",
      "       'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
      "       'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive',\n",
      "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #imports pandas for data manipulation\n",
    "train_file_path = 'train.csv' #declares a file path for the training data that will be used\n",
    "test_file_path = 'test.csv'\n",
    "data = pd.read_csv(train_file_path) # creates a dataframe object using the filepath\n",
    "testdata = pd.read_csv(train_file_path)\n",
    "\n",
    "columns = data.columns #creates a list of columns (as strings)\n",
    "columns_with_empty = [] #empty list of columns that have empty values\n",
    "for i in columns: #for each \"i\" in the list of columns\n",
    "    if data[i].isnull().any(): #if that column (data[i]) has any NaN values, add it to the columns_with_empty list\n",
    "        columns_with_empty.append(i)\n",
    "print('These are the columns that have empty values:\\n\\n'+ str(columns_with_empty) + '\\n') #print all columns with empty values\n",
    "\n",
    "dataNaN = data.isnull() #creates a new dataframe identical in size to \n",
    "#data but with true and false replacing the actual values in each data frame (true being a missing value)\n",
    "\n",
    "columnSum = dataNaN.sum() #creates a series (One-dimensional ndarray with axis labels) of \n",
    "#every column and its sum (number of true, or previously missing values)\n",
    "\n",
    "print('These are the numbers of \\'NaN\\' values in for every column in the data:\\n\\n' + str(columnSum) + '\\n')\n",
    "#help(columnSum) used to determine what kind of object it is and how it works, what can be doen with it etc.\n",
    "\n",
    "data[columns_with_empty].isnull().sum() #uses both methods above to return a series of only the columns with an empty\n",
    "#value and the amount of empty values in that columns\n",
    "\n",
    "data_without_nan = data.dropna(axis = 'columns') #you can also omit rows data.dropna() to remove individual values\n",
    "print('These are the new data columns with the columns that had \\'NaN\\' values dropped\\n\\n' + str(data_without_nan.columns)+'\\n') \n",
    "# prints the new data columns without the columns that had null values\n",
    "\n",
    "testdata_without_nan = testdata.drop(columns_with_empty, axis = 'columns') # drops the columns from test data too, then prints it below\n",
    "print(testdata_without_nan.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation: Imputation 'infers' a value to fill in for the missing value so that the column can still be used. \n",
    "\n",
    "#### 9: Import imputer for later use\n",
    "\n",
    "#### 10: Create a copy of the data and remove everything everything except for number only categories to help imputation, as well as the SalePrice data (we are going to be predicting it).\n",
    "\n",
    "#### 11: Impute the data, storing it into a new DataFrame\n",
    "\n",
    "### Now we are doing an extenstion on imputation:\n",
    "\n",
    "#### 12: Once again, find the columns with missing values and store it in a list. However, then create a new column of whether or not the value was NaN or not (and therefore imputed or not).\n",
    "\n",
    "#### 13: Impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
      "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
      "       'MiscVal', 'MoSold', 'YrSold', 'LotFrontage_was_missing',\n",
      "       'MasVnrArea_was_missing', 'GarageYrBlt_was_missing'],\n",
      "      dtype='object')\n",
      "0        65.0\n",
      "1        80.0\n",
      "2        68.0\n",
      "3        60.0\n",
      "4        84.0\n",
      "5        85.0\n",
      "6        75.0\n",
      "7         NaN\n",
      "8        51.0\n",
      "9        50.0\n",
      "10       70.0\n",
      "11       85.0\n",
      "12        NaN\n",
      "13       91.0\n",
      "14        NaN\n",
      "15       51.0\n",
      "16        NaN\n",
      "17       72.0\n",
      "18       66.0\n",
      "19       70.0\n",
      "20      101.0\n",
      "21       57.0\n",
      "22       75.0\n",
      "23       44.0\n",
      "24        NaN\n",
      "25      110.0\n",
      "26       60.0\n",
      "27       98.0\n",
      "28       47.0\n",
      "29       60.0\n",
      "        ...  \n",
      "1430     60.0\n",
      "1431      NaN\n",
      "1432     60.0\n",
      "1433     93.0\n",
      "1434     80.0\n",
      "1435     80.0\n",
      "1436     60.0\n",
      "1437     96.0\n",
      "1438     90.0\n",
      "1439     80.0\n",
      "1440     79.0\n",
      "1441      NaN\n",
      "1442     85.0\n",
      "1443      NaN\n",
      "1444     63.0\n",
      "1445     70.0\n",
      "1446      NaN\n",
      "1447     80.0\n",
      "1448     70.0\n",
      "1449     21.0\n",
      "1450     60.0\n",
      "1451     78.0\n",
      "1452     35.0\n",
      "1453     90.0\n",
      "1454     62.0\n",
      "1455     62.0\n",
      "1456     85.0\n",
      "1457     66.0\n",
      "1458     68.0\n",
      "1459     75.0\n",
      "Name: LotFrontage, Length: 1460, dtype: float64\n",
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "5       False\n",
      "6       False\n",
      "7        True\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12       True\n",
      "13      False\n",
      "14       True\n",
      "15      False\n",
      "16       True\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20      False\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24       True\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "1430    False\n",
      "1431     True\n",
      "1432    False\n",
      "1433    False\n",
      "1434    False\n",
      "1435    False\n",
      "1436    False\n",
      "1437    False\n",
      "1438    False\n",
      "1439    False\n",
      "1440    False\n",
      "1441     True\n",
      "1442    False\n",
      "1443     True\n",
      "1444    False\n",
      "1445    False\n",
      "1446     True\n",
      "1447    False\n",
      "1448    False\n",
      "1449    False\n",
      "1450    False\n",
      "1451    False\n",
      "1452    False\n",
      "1453    False\n",
      "1454    False\n",
      "1455    False\n",
      "1456    False\n",
      "1457    False\n",
      "1458    False\n",
      "1459    False\n",
      "Name: LotFrontage_was_missing, Length: 1460, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "newdata = data.copy() #creates a copy of the data called newdata\n",
    "newdata = newdata.select_dtypes(exclude=['object']) #selects only integer (maybe float?) values for simplification\n",
    "newdata = newdata.drop(['SalePrice'], axis = 'columns') #drops the saleprice column as that's what we're PREDICTING\n",
    "\n",
    "my_imputer = Imputer() #creates an imputer\n",
    "#help(my_imputer) tells us parameters and other useful info about the imputers\n",
    "data_with_imputed_values = my_imputer.fit_transform(newdata) #has the imputer impute for the NaN values\n",
    "\n",
    "#Imputation with an extension:\n",
    "\n",
    "cols_with_missing = [] #defines an empty list for the columns with missing values\n",
    "for i in newdata.columns:\n",
    "    if newdata[i].isnull().any(): #if any value in the given column is null add it to the list\n",
    "        cols_with_missing.append(i)\n",
    "for col in cols_with_missing: #going through each column that had a missing value, \n",
    "    #create a new column to show what values were inputed\n",
    "    newdata[col + '_was_missing'] = newdata[col].isnull()\n",
    "    \n",
    "print(newdata.columns) #print all the columns (it will show the new _was_missing columns and not the dropped ones)\n",
    "print(newdata.LotFrontage) #print the lotFrontage data to show the NaN values\n",
    "print(newdata.LotFrontage_was_missing) #print the wasmissing for lotfrontage to show how they match up\n",
    "\n",
    "newdata = my_imputer.fit_transform(newdata) #inputs the data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together for some final model analysis:\n",
    "\n",
    "#### 14: Import necessary packages.\n",
    "\n",
    "#### 15: Import the dataset as a DataFrame, and identify the y value.\n",
    "\n",
    "#### 16: Drop the values that are 'objects' (not numbers) so that the imputation and model can run correctly, as well as the SalePrice data. Store this as newtraindata which will be used for later models, and create a copy called x for the current model (dropping columns).\n",
    "\n",
    "#### 17: Identify every empty column, store it in a list, and then drop it from x, removing any columns that have a NaN value.\n",
    "\n",
    "#### 18: Split the data into testing and training sets, then create a model with optimal values and calculate the mean absolute error(MAE).\n",
    "\n",
    "#### 19: Create a new object imputeddata as a copy of newtraindata, which has the sales and non number categories dropped. \n",
    "\n",
    "#### 20: Apply the imputation, split it, train the model, and print the MAE.\n",
    "\n",
    "#### 21: Finally, create another copy of newtraindata, imputeddata2, and add a new boolean combo for every column that had a missing value that describes whether or not it was missing.\n",
    "\n",
    "#### 22: Creates a new model and prints the MAE using this dataset.\n",
    "\n",
    "### Overall, we can see that removing the columns actually had a slightly effect on the data than the imputation or the enhanced imputation, but the enhanced imputation was verrrry slightly improved on the regular one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
      "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
      "       'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object')\n",
      "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
      "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
      "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
      "       'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
      "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars',\n",
      "       'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object')\n",
      "17229.9129027\n",
      "17481.6549548\n",
      "17442.2485548\n",
      "As you can see, removing the categories was actually much more effective for this dataset, \n",
      "likely due to the low amount of columns that had missing data. You can also see that the Imputation \n",
      "with extension slightly improved upon regular Imputation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split #imports\n",
    "\n",
    "trainpath = 'train.csv'\n",
    "traindata = pd.read_csv(trainpath)\n",
    "y = traindata.SalePrice #creates the traindata DataFrame from csv and the y values\n",
    "\n",
    "newtraindata = traindata.select_dtypes(exclude=['object']) #removes any non number values from the traindata and stores it into a new value, newtraindata\n",
    "newtraindata = newtraindata.drop(['SalePrice'], axis = 'columns') #removes the SalePrice column(y values) from the x values\n",
    "x = newtraindata #x is a copy of newtraindata to be used for the first model\n",
    "\n",
    "\n",
    "columns_with_empty = [] #defines an empty list of columns that have empty values\n",
    "print(x.columns) #print the columns that are still in the data \n",
    "\n",
    "for i in x.columns:\n",
    "    if x[i].isnull().any():\n",
    "        columns_with_empty.append(i) #goes through every column and if it has an NaN value, appends it to columns_with_empty\n",
    "x = x.drop(columns_with_empty, axis = 'columns') #from x specifically for the first model, removes any columns that have empty values \n",
    "print(columns_with_empty) #print the columns that were just removed       \n",
    "print(x.columns) #print the columns that are left\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0) #splits the data into testing and training sets\n",
    "\n",
    "RFmodel1 = RandomForestRegressor(n_estimators = 2000)\n",
    "RFmodel1.fit(train_x, train_y)\n",
    "predicted = RFmodel1.predict(val_x)\n",
    "#creates and trains the model, we've done this before\n",
    "print(mean_absolute_error(val_y, predicted)) #print the MAE of actual y values and the model predicted ones\n",
    "\n",
    "imputeddata = newtraindata.copy() #creates another copy of newtraindata for the second model\n",
    "myimputer = Imputer() #creates the imputer\n",
    "imputeddata = myimputer.fit_transform(imputeddata) #imputes the data, filling in the values that are NaN\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(imputeddata, y, random_state=0) #splits the data *after* imputing\n",
    "\n",
    "RFmodel2 = RandomForestRegressor(n_estimators = 2000)\n",
    "RFmodel2.fit(train_x, train_y)\n",
    "predicted = RFmodel2.predict(val_x)\n",
    "\n",
    "print(mean_absolute_error(val_y, predicted))#print the MAE of actual y values and the mode predicted ones\n",
    "\n",
    "imputeddata2 = newtraindata.copy() #creates a final copy of newtraindata for the third model\n",
    "\n",
    "for i in columns_with_empty:\n",
    "    imputeddata2[i + '_was_empty'] = imputeddata2[i].isnull() #adds columns for the columns that had missing values and which ones were missing with booleans\n",
    "\n",
    "imputeddata2 = myimputer.fit_transform(imputeddata2) #impute the data\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(imputeddata, y, random_state = 0)\n",
    "\n",
    "RFmodel3 = RandomForestRegressor(n_estimators = 2000)\n",
    "RFmodel3.fit(train_x, train_y)\n",
    "predicted = RFmodel3.predict(val_x)\n",
    "\n",
    "print(mean_absolute_error(val_y, predicted)) #print the MAE of actual y values and the model predicted ones\n",
    "\n",
    "print(\"\"\"As you can see, removing the categories was actually much more effective for this dataset, \n",
    "likely due to the low amount of columns that had missing data. You can also see that the Imputation \n",
    "with extension slightly improved upon regular Imputation.\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
