{
  "cells": [
    {
      "metadata": {
        "_uuid": "1b2e8b592694d84d212ab3bd6aa231a7793868b3",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "{\"cells\":[{\"metadata\":{\"_uuid\":\"b6269c0e8f417f82daf093dda8fa0da6d2c57d86\",\"_cell_guid\":\"e81ee64d-e474-4662-9036-ce23df615199\"},\"cell_type\":\"markdown\",\"source\":\"# Introduction\\n**This will be your workspace for the [Machine Learning course](https://www.kaggle.com/learn/machine-learning).**\\n\\nYou will need to translate the concepts to work with the data in this notebook, the Iowa data. Each page in the Machine Learning course includes instructions for what code to write at that step in the course.\\n\\n# Write Your Code Below\"},{\"metadata\":{\"collapsed\":true,\"_uuid\":\"1c728098629e1301643443b1341556a15c089b2b\",\"_cell_guid\":\"86b26423-563a-4fa1-a595-89e25ff93089\",\"trusted\":false},\"cell_type\":\"code\",\"source\":\"import pandas as pd\\n\\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\\ndata = pd.read_csv(main_file_path)\\n\\n# Run this code block with the control-enter keys on your keyboard. Or click the blue botton on the left\\nprint('Some output from running this cell')\",\"execution_count\":null,\"outputs\":[]},{\"metadata\":{\"_uuid\":\"64fde43ae8511da761549c42f24eccb5d1039271\",\"_cell_guid\":\"06a2e301-f224-40d0-8709-a942b24cd124\"},\"cell_type\":\"markdown\",\"source\":\"\\n**If you have any questions or hit any problems, come to the [Learn Discussion](https://www.kaggle.com/learn-forum) for help. **\\n\\n**Return to [ML Course Index](https://www.kaggle.com/learn/machine-learning)**\"},{\"metadata\":{\"_uuid\":\"704e07440d7d4ef7ad3cf25c0a966c000bb8eeef\",\"_cell_guid\":\"895df7f1-dab8-4c54-ab7e-9a865146deac\"},\"cell_type\":\"markdown\",\"source\":\"\"}],\"metadata\":{\"language_info\":{\"name\":\"python\",\"version\":\"3.6.5\",\"mimetype\":\"text/x-python\",\"codemirror_mode\":{\"name\":\"ipython\",\"version\":3},\"pygments_lexer\":\"ipython3\",\"nbconvert_exporter\":\"python\",\"file_extension\":\".py\"},\"kernelspec\":{\"display_name\":\"Python 3\",\"language\":\"python\",\"name\":\"python3\"}},\"nbformat\":4,\"nbformat_minor\":1}"
    },
    {
      "metadata": {
        "_uuid": "bd549f7ff2f25db046a954c8a97685ed533a50a9",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd #\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' #set a string for the file path of your csv file\ndata = pd.read_csv(main_file_path) #create a data object/variable from the file path string using the pandas read_csv method\nprint(data.columns) #print the columns of the data using the column method in order to ascertain what variables there are",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "26198ed68c08447761f06891949e632142e94e7a"
      },
      "cell_type": "code",
      "source": "saleprice_data = data.SalePrice #use dot notation (to get a field of the data object) that aligns with the colum you are looking for\n#print(saleprice_data.head()) # print the top few entries of the data colum selected",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9099ed87b6fb0c82088419b75f8475829ca2eaec",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "listofcolumns = ['Neighborhood','YearBuilt']  #create a list using column names that are of interest\ntwodatacolumns = data[listofcolumns] # \"splice\" the data using the list of relevant combos\nprint(twodatacolumns) #why does this \"work\" but not describe?\ntwodatacolumns.describe() #describes the smaller data sheet created\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13d533d615e2205d35ac0e804ada0ce0c7c7e64c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y = saleprice_data #define your y variable (what will be predicted), we already did this above\nlistofxvalues = ['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']# the x values being used\nx = data[listofxvalues] # once again splice the data into the values we are looking for\nfrom sklearn.tree import DecisionTreeRegressor #imports the regression system\niowamodel = DecisionTreeRegressor() #declare a model object\niowamodel.fit(x,y) # train the model using the x and y declared above",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f102a7de9f1631585b900ab75bb21bd7b75fab6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('making predictions for the following five houses:')\nprint(x.head()) # top 5 lines of the column\nprint('the predictions are:')\nprint(iowamodel.predict(x.head())) #using the trained model predict y values from those x value\nprint('the actual values:')\nprint(y.head()) #actual first 5 price values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3cecf3d7f756b8ec3e41f03431769495dde6536d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error #import to find mean absolute error (simple residual)\npredictedvalues = iowamodel.predict(x) #predict A L L of the possibilities\nmean_absolute_error(y, predictedvalues) #calculate and print error",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4e5b984707f097593cd2be679da629bf7b6c48f",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split #okay so now we are going to split the data set between training and predicting to actually test the effectiveness of the model as well as to prevent biases from interpolation\n\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, random_state =0) #WHEW okay so we have a tuple of values setup that is equal to this method that uses a RNG to determine which values are in each category\niowamodel2 = DecisionTreeRegressor() #creating a new model\niowamodel2.fit(train_x, train_y) #training the model using the specified training data\npredictions =  iowamodel2.predict(val_x) #predicts the values\nmean_absolute_error(val_y, predictions) #finds the total mean absolute error and prints",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae2f0a87c05f878887a652de1e717c3d57bc00ae",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def mae(numleaves, trainx, trainy, valx, valy):#defining a neat function that calculates the average residual for us. neat! used to rpevent over or underfitting from the model\n    model = DecisionTreeRegressor(max_leaf_nodes=numleaves, random_state=0) #some more fancy schmancy stuff, but basically it creates a model with some specific attributes, notably the number of leaves and the random state agaiuun? dont know what random state is for\n    model.fit(trainx, trainy) #just training the model, though we could pass a model as an argument if necessary\n    predicted = model.predict(valx) #once again predicts values\n    return (mean_absolute_error(valy, predicted))#returns the average residual!\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, random_state =0) #once again splitting the model into test sets \nmin = 999999999 # arbitrarily setting up a very large value to detect a min\nnum = 0 #declaring a variable that will print out the best leaf config\nfor i in [75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]: #for loop through a list of a bunch of possible values. rn i manually\n    result = mae(i, train_x, train_y, val_x, val_y)#calculates a result through the values\n    if result < min: #testing to find min value\n        min = result\n        num = i\n    print(result)\nprint(' the leaf configuration that best fits is: %s and the value calculated is %s' %(num, min))\n\n\n\n    \n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d345beee1565492a724981e6fa364586f435b7a"
      },
      "cell_type": "code",
      "source": "#This is me using the techniques I've learned throughout this course in one block to show how to create these models\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor #importing a different regression method\nfrom sklearn.metrics import mean_absolute_error # import residual function\nfrom sklearn.model_selection import train_test_split #splits data\n\ndirectory = '../input/house-prices-advanced-regression-techniques/train.csv' #once again declaring a directory variable as string\ndata = pd.read_csv(directory) #create a data frame using pandas from the csv file\n\ny = data.SalePrice # uses dot notation to identify what we are predicting\nxlist = ['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd'] #defines an x list of columns/features to be used\nx = data[xlist] #creating our x data using slicing with our list\n\n\ntrain_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0) #splits the data into test and train sets\nmin = 99999999999999\ng = 0\nfor i in (5, 25, 50, 75, 100, 200, 500, 1000, 2000): #tests different values for n_estimators, explained in the comments below\n    model = RandomForestRegressor(n_estimators = i, random_state =0) #instantiate model using a different value, still unsure as to what random_state does\n    model.fit(train_x, train_y) # fit the model with training data\n    predicted = model.predict(val_x) #define predicted value\n    mae = mean_absolute_error(val_y, predicted)\n    if(mae < min):\n        min = mae\n        g = i\n    print('n_estimators: %s \\t\\t MAE: %s'%(i, mae)) # print the MAE (avergae residual) \nprint('The best fit for these values is an n_estimators value of %s with an MAE of %s'%(g, min))\n\n #http://scikit-learn.org/stable/modules/ensemble.html#forest\n #The main parameters to adjust when using these methods is n_estimators and max_features. \n #The former is the number of trees in the forest. The larger the better, but also the longer it will take to compute. \n #In addition, note that results will stop getting significantly better beyond a critical number of trees. \n #The latter is the size of the random subsets of features to consider when splitting a node. \n #The lower the greater the reduction of variance, but also the greater the increase in bias. \n\nmodel = RandomForestRegressor(n_estimators = 1000, random_state =0) #building a final model\nmodel.fit(x, y) #fitting the model with data, no splitting\ntestdata = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv') #declaring the testdata as a separate csv\ntestx = testdata[xlist] \npredictedprices = model.predict(testx)\n#not yet tested, Kaggle stopped working for me for a second. \nsubmission = pd.DataFrame({'Id':testdata.Id, 'SalePrice':predictedprices})\nsubmission.to_csv('submisson.csv', index=False)\n\n\n        \n",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": "n_estimators: 5 \t\t MAE: 25330.813515981736\nn_estimators: 25 \t\t MAE: 23591.653607305936\nn_estimators: 50 \t\t MAE: 23242.58928767123\nn_estimators: 75 \t\t MAE: 22964.54597260274\nn_estimators: 100 \t\t MAE: 23093.063676581867\nn_estimators: 200 \t\t MAE: 23007.87736470972\nn_estimators: 500 \t\t MAE: 22907.489858734512\nn_estimators: 1000 \t\t MAE: 22909.57230941944\nn_estimators: 2000 \t\t MAE: 22897.42493080492\nThe best fit for these values is an n_estimators value of 2000 with an MAE of 22897.42493080492\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "862ce547a0061d37587c8efaf6c550ff7970ff71"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}